# Deep-Learning

1. Deep Learning Introduction

        ğŸ”´Deep Learning Introduction
        ğŸ”´Types of Neural Networks
        ğŸ”´Multilayer Perceptron and Backpropagation
        ğŸ”´Keras Basic Regression Project
        ğŸ”´Keras Basic Classification Project
        ğŸ”´Tensorboard
        ğŸ”´Fine Tuning Hyper-Parameters
 2. Training Deep Neural Networks 
 
        ğŸ”´Vanishing/ Exploding Gradient Problem
        ğŸ”´Non- Saturating Activation Functions
        ğŸ”´Batch Normalization
        ğŸ”´Gradient Clipping
        ğŸ”´Reusing Pretrained Layer
        ğŸ”´Faster Optimizers
        ğŸ”´Momentum Optimizers
        ğŸ”´Ada Grad
        ğŸ”´RMS Propagation
        ğŸ”´Adam and Nadam Propagation
        ğŸ”´Learning Rate Scheduling
        ğŸ”´L1 L2 Regularization
        ğŸ”´Drop- Out and Monte Carlo Drop Out
    
3. Tensorflow

        ğŸ”´Overview of Tensorflow
        ğŸ”´Custom Loss Function
        ğŸ”´Custom Activation Functions, Regularizers and Constraints
        ğŸ”´Custom Metrics
        ğŸ”´Custom Layer
        ğŸ”´Custom Models
        ğŸ”´Computing Gradients using AutoDiff and Custom Training Loops
        ğŸ”´Data API
        ğŸ”´Chain Transformations
        ğŸ”´Shuffling the Data
        ğŸ”´TF Records
        ğŸ”´Features API
